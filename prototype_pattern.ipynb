{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cython\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  122  ms\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('flies.jpg')\n",
    "\n",
    "#opencv output\n",
    "WINDOW_DIMS = (1500, 200)\n",
    "\n",
    "#pipeline constants\n",
    "WHITE_RGB = np.array([255, 255, 255], dtype=np.uint8)\n",
    "DISTANCE_THRESHOLD = 10\n",
    "GRAYSCALE_THRESHOLD = 120\n",
    "RESIZE_FACTOR = 100 #pixels of the largest boarder\n",
    "LOW_PASS_FILTER_KERNEL_DIMS = (4, 4)\n",
    "BLOBS_SIZES_BOUNDS = (7, 10)\n",
    "SUBSET_IMG_SIDE_LENGTH = None\n",
    "\n",
    "\n",
    "#for the blob detection\n",
    "BLOB_DETECTOR_PARAMS = cv.SimpleBlobDetector_Params()\n",
    "BLOB_DETECTOR_PARAMS.filterByConvexity = False\n",
    "BLOB_DETECTOR_PARAMS.filterByCircularity = False\n",
    "BLOB_DETECTOR_PARAMS.filterByInertia = False\n",
    "BLOB_DETECTOR_PARAMS.filterByArea = False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "this method takes a vector of rgb components @rgb_vec and\n",
    "replace it with @replace if the average absolute difference\n",
    "with each component regarding the average of the components\n",
    "exceeds the threshold. In other word, this function aim to\n",
    "replace the vector by another if the pixel is not as grayscaled\n",
    "as we want\n",
    "\"\"\"\n",
    "def compute_avg_diff_comp(rgb_vec, replace, thresh):\n",
    "    assert(rgb_vec.shape[0] == 3)\n",
    "    mean = np.mean(rgb_vec)\n",
    "    sub = np.abs(rgb_vec - mean)\n",
    "    sub_mean = np.max(sub)\n",
    "    if (sub_mean < thresh):\n",
    "        return rgb_vec\n",
    "    else:\n",
    "        return replace\n",
    "        \n",
    "\"\"\"\n",
    "this methods takes an image and filter it with @compute_avg_diff_comp\n",
    "the resulting image is an image where the pixels not satisfying the threshod\n",
    "are full white.\n",
    "\"\"\"\n",
    "def filter_threshold_colored_pixels(img):\n",
    "    global WHITE_RGB\n",
    "    global DISTANCE_THRESHOLD\n",
    "    result = []\n",
    "    for i in range(0, len(img)):\n",
    "        for j in range(0, len(img[0])):\n",
    "            rgb_vec = img[i][j]\n",
    "            result.append(compute_avg_diff_comp(rgb_vec, WHITE_RGB, DISTANCE_THRESHOLD))\n",
    "    result = np.asarray(result, dtype=np.uint8)\n",
    "    result = result.reshape((img.shape[0], img.shape[1], img.shape[2]))\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "convert an rgb numpy array to a grayscale numpy array\n",
    "the type must be uint8 for each component\n",
    "\"\"\"\n",
    "def convert_rgb_to_grayscale(img):\n",
    "    return cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "\"\"\"\n",
    "convert permute all the red and blue channels of an image.\n",
    "This is needed for opencv\n",
    "\"\"\"\n",
    "def convert_bgr_to_rgb(img):\n",
    "    return cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "\"\"\"\n",
    "given a grayscale image, set the pixel having \n",
    "brightness greater than threshold to white\n",
    "\"\"\"\n",
    "def filter_threshold_binary_grayscale_to_white(img):\n",
    "    global GRAYSCALE_THRESHOLD\n",
    "    img[img > GRAYSCALE_THRESHOLD] = 255\n",
    "    return img\n",
    "\n",
    "\"\"\"\n",
    "set all non white pixels to black\n",
    "\"\"\"\n",
    "def filter_threshold_binary_non_white_to_black(img):\n",
    "    img[img != 255] = 0\n",
    "    return img\n",
    "\n",
    "\"\"\"\n",
    "this function resize the image by a RESIZE_FACTOR\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def resize_img(img):\n",
    "    global RESIZE_FACTOR\n",
    "    width = int(img.shape[1] * RESIZE_FACTOR / 100)\n",
    "    height = int(img.shape[0] * RESIZE_FACTOR / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "    return resized\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "this function resize the image by a RESIZE_FACTOR\n",
    "\"\"\"\n",
    "def resize_img(img):\n",
    "    global RESIZE_FACTOR\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    max_dim = max(width, height)\n",
    "    width_adjusted = int((width / max_dim) * RESIZE_FACTOR)\n",
    "    height_adjusted = int((height / max_dim) * RESIZE_FACTOR)\n",
    "    dim_adjuted = (width_adjusted, height_adjusted)\n",
    "    resized = cv.resize(img, dim_adjuted, interpolation = cv.INTER_AREA)\n",
    "    return resized\n",
    "    \n",
    "\"\"\"\n",
    "This functions apply a low pass filter kernel to the image\n",
    "\"\"\"\n",
    "def filter_low_pass_img(img):\n",
    "    global LOW_PASS_FILTER_KERNEL_DIMS\n",
    "    return cv.blur(img, LOW_PASS_FILTER_KERNEL_DIMS)\n",
    "\n",
    "\"\"\"\n",
    "find all the blobs in the image and highlight them.\n",
    "We also return a list of the blob sizes\n",
    "\"\"\"\n",
    "def find_blobs(img):\n",
    "    global BLOB_DETECTOR_PARAMS\n",
    "    detector = cv.SimpleBlobDetector_create(BLOB_DETECTOR_PARAMS)\n",
    "    keypoints = detector.detect(img)\n",
    "    blobs_sizes = []\n",
    "    for k in keypoints:\n",
    "        blobs_sizes.append(k.size)\n",
    "    blobs_sizes = np.array(blobs_sizes)\n",
    "    return cv.drawKeypoints(img, keypoints, np.array([]), (0,0,255), cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS), blobs_sizes\n",
    "\n",
    "\"\"\"\n",
    "set all boarders pixels of the image to the value given as argument\n",
    "\"\"\"\n",
    "def set_image_boarders(img, value):\n",
    "    assert(value >= 0 and value <= 255)\n",
    "    w = img.shape[1]\n",
    "    h = img.shape[0]\n",
    "    img[0, :, ] = value\n",
    "    img[h - 1, :, ] = value\n",
    "    img[:, 0, ] = value\n",
    "    img[:, w - 1, ] = value\n",
    "    return img\n",
    "\n",
    "\"\"\"\n",
    "this function removes any external layer of pixel in the border of the\n",
    "image. This is helpful for the blob detection part.\n",
    "\"\"\"\n",
    "def set_boarders_white(img):\n",
    "    return set_image_boarders(img, 255)\n",
    "\n",
    "\n",
    "def set_boarders_black(img):\n",
    "    return set_image_boarders(img, 0)\n",
    "\n",
    "\n",
    "def get_img_centered_square_subset(img, size):\n",
    "    width = int(img.shape[1])\n",
    "    height = int(img.shape[0])\n",
    "    assert(size <= max(width, height))\n",
    "    mid = (width // 2, height // 2)\n",
    "    size_half = size // 2\n",
    "    bottom_left = (mid[0] - size_half, mid[1] - size_half)\n",
    "    top_left = (mid[0] - size_half, mid[1] + size_half)\n",
    "    bottom_right = (mid[0] + size_half, mid[1] - size_half)\n",
    "    \n",
    "    print(bottom_left)\n",
    "    print(top_left)\n",
    "    print(bottom_right)\n",
    "    \n",
    "    return img[bottom_left[1]:top_left[1], bottom_left[0]:bottom_right[0], ]\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "preproessing pipeline:\n",
    "\n",
    "1. we resize the image \n",
    "    This allows us to remove a bit of noise and to allows more efficient calculations\n",
    "2. We filter the colored objects to white\n",
    "    Since a fly is gray to black we want to get rid of all the colored pixels in the image\n",
    "3. We convert the resulting image to grayscale because now all three components are almost equal\n",
    "4. We filter pixels by their brightness since a fly is dark\n",
    "5. We filter all non white pixels to black because each non white pixel at this point is a good\n",
    "    candidate for belonging to a fly\n",
    "6. We blur the image to remove high frequency data occuring\n",
    "7. We filter again all non white pixel to black, this enlight area of interest\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "pipeline = [\n",
    "    (resize_img_2, \"resized\"),\n",
    "    (filter_threshold_colored_pixels, \"filter colored pixel\"),\n",
    "    (convert_rgb_to_grayscale, \"convert to grayscale\"),\n",
    "    (filter_threshold_binary_grayscale_to_white, \"threshold brightness\"),\n",
    "    (filter_threshold_binary_non_white_to_black, \"set non white to black\"),\n",
    "    (filter_low_pass_img, \"low pass filter\"),\n",
    "    (filter_threshold_binary_non_white_to_black, \"set non white to black again\"),\n",
    "    (set_boarders_white, \"remove external pixel line\")\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "pipeline processing the image in order to prepare it to be detected\n",
    "this function should only be used in a python notebook\n",
    "\"\"\"\n",
    "def preprocessing_pipeline_matplotlib(img):\n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(len(pipeline) + 2, 1, figsize=(40, 40)) \n",
    "    axarr[0].set_title(\"orignial input \" + str(img.shape[1]) + \"x\" + str(img.shape[0]))\n",
    "    axarr[0].imshow(img)\n",
    "    \n",
    "    pipeline_result_img = None\n",
    "    \n",
    "    for i in range(1, len(pipeline) + 1):\n",
    "        pipeline_step = pipeline[i - 1]\n",
    "        func = pipeline_step[0]\n",
    "        img = func(img)\n",
    "        \n",
    "        if (i == len(pipeline) - 1):\n",
    "            pipeline_result_img = img\n",
    "        \n",
    "        if (len(img.shape) == 3):\n",
    "            assert(img.shape[2] == 3)\n",
    "            axarr[i].imshow(img)\n",
    "        else:\n",
    "            axarr[i].imshow(img, cmap = plt.cm.gray)\n",
    "        axarr[i].set_title(pipeline_step[1] + \" \" + str(img.shape[1]) + \"x\" + str(img.shape[0]))\n",
    "    \n",
    "    assert(pipeline_result_img is not None)\n",
    "    detection_image, blob_sizes = find_blobs(pipeline_result_img)\n",
    "    axarr[len(pipeline) + 1].imshow(detection_image)\n",
    "    axarr[len(pipeline) + 1].set_title(\"found \" + str(len(blob_sizes)) + \" blobs\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return img\n",
    "\n",
    " \n",
    "#preprocessed_img = preprocessing_pipeline_matplotlib(convert_bgr_to_rgb(img))\n",
    "\n",
    "\n",
    "\"\"\"returns an image with all the pipeline\"\"\"\n",
    "def pipeline_opencv(img):\n",
    "    images = []\n",
    "    pipeline_result_img = None\n",
    "    \n",
    "    for i in range(0, len(pipeline)):\n",
    "        pipeline_step = pipeline[i]\n",
    "        func = pipeline_step[0]\n",
    "        img = func(img)\n",
    "        \n",
    "        if (i == len(pipeline) - 1):\n",
    "            pipeline_result_img = img\n",
    "        \n",
    "        img_cpy_black_boarders = set_boarders_black(img.copy())\n",
    "        #if the output is colored or not\n",
    "        if (len(img.shape) == 3):\n",
    "            assert(img.shape[2] == 3)\n",
    "            images.append(img_cpy_black_boarders)\n",
    "        else:\n",
    "            images.append(cv.cvtColor(img_cpy_black_boarders, cv.COLOR_GRAY2BGR))\n",
    "            \n",
    "    assert(pipeline_result_img is not None)\n",
    "    detection_image, blob_sizes = find_blobs(pipeline_result_img)\n",
    "    images.append(set_boarders_black(detection_image))\n",
    "    \n",
    "    return np.concatenate(images, axis=1), blob_sizes\n",
    "\n",
    "\n",
    "starting_time = round(time.time() * 1000)\n",
    "res, blob_sizes = pipeline_opencv(img)\n",
    "print(\"t = \", str(round(time.time() * 1000) - starting_time), \" ms\")\n",
    "\n",
    "cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "cv.resizeWindow('result', WINDOW_DIMS[0], WINDOW_DIMS[1])\n",
    "cv.imshow('result', res)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feb9a4f28e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_external_line(img):\n",
    "    w = img.shape[1]\n",
    "    h = img.shape[0]\n",
    "    img[0, :, ] = 255\n",
    "    img[h - 1, :, ] = 255\n",
    "    img[:, 0, ] = 255\n",
    "    img[:, w - 1, ] = 255\n",
    "    return img\n",
    "    \n",
    "plt.imshow(remove_external_line(preprocessed_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save 06.06.21\n",
    "def compute_pattern(h, w):\n",
    "    return np.ones((h, w), np.uint8)\n",
    "\n",
    "pattern = compute_pattern(6, 6)\n",
    "\n",
    "def find_box_with_pattern(img, pattern):\n",
    "    \n",
    "    pattern_img_cpy = pattern.copy()\n",
    "    methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "    meth = methods[4]\n",
    "    w, h = pattern.shape[::-1]\n",
    "    \n",
    "    method = eval(meth)\n",
    "    current_target = img.copy()\n",
    "    neighborhood_img = cv.matchTemplate(current_target, pattern_img_cpy, method)\n",
    "    \n",
    "    return neighborhood_img\n",
    "\n",
    "result_img = find_box_with_pattern(preprocessed_img, pattern)\n",
    "resized = resize_img(img)\n",
    "resized_rgb = convert_bgr_to_rgb(resized)\n",
    "\n",
    "threshold = 0.01\n",
    "result_img = (result_img - np.std(result_img)) / np.mean(result_img)\n",
    "loc = np.where(result_img < threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv.rectangle(resized_rgb, pt, (pt[0] + 1, pt[1] + 1), (0,0,255), 1)\n",
    "    \n",
    "plt.figure()\n",
    "f2, axarr2 = plt.subplots(1, 2, figsize=(15,15)) \n",
    "axarr2[0].imshow(result_img, cmap = plt.cm.gray)\n",
    "axarr2[1].imshow(resized_rgb)\n",
    "\n",
    "plt.show()\n",
    "np.max(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'flies2.jpg'\n",
    "patterns = ['fly.jpg', 'fly1.png', 'fly2.png', 'fly3.png', 'fly4.png']\n",
    "patterns = ['pattern/' + p for p in patterns]\n",
    "\n",
    "target_img = cv.imread(target, 0)\n",
    "target_img_colored = cv.imread(target)\n",
    "\n",
    "target_dim = (target_img.shape[1], target_img.shape[0])\n",
    "fly_dim_pixel = (target_dim[0] // 7, target_dim[1] // 5)\n",
    "\n",
    "print(target_dim)\n",
    "print(fly_dim_pixel)\n",
    "\n",
    "patterns_imgs = [ cv.imread(p,0) for p in patterns]\n",
    "\n",
    "\"\"\"resize the images so that they are in the target\"\"\"\n",
    "def resize_for_target(img, target_dim):\n",
    "    return cv.resize(img, target_dim, interpolation = cv.INTER_AREA)\n",
    "\n",
    "def resize_with_factor(img, factor):\n",
    "    dim = (img.shape[1], img.shape[0])\n",
    "    dim = (int(dim[0] * factor), int(dim[1] * factor))\n",
    "    return cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "\n",
    "patterns_imgs = [resize_for_target(p, fly_dim_pixel) for p in patterns_imgs]\n",
    "    \n",
    "\"\"\"Find the pattern in the target and returns the top-left and bottom right corners if found\"\"\"\n",
    "def find_box_with_pattern(target_img, pattern_img):\n",
    "    pattern_img_cpy = pattern_img.copy()\n",
    "    methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "    meth = methods[0]\n",
    "    w, h = pattern_img.shape[::-1]\n",
    "    \n",
    "    method = eval(meth)\n",
    "    current_target = target_img.copy()\n",
    "    result = cv.matchTemplate(current_target, pattern_img_cpy, method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "        \n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "            \n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    \n",
    "    print(str(min_val) + \" \" + str(max_val))\n",
    "    \n",
    "    if (max_val < 7000000):\n",
    "        return None\n",
    "    \n",
    "    return (top_left, bottom_right)\n",
    "\n",
    "\n",
    "\"\"\"find a set of corners matching the patterns in the target\"\"\"\n",
    "def find_for_all_patterns(target_img, patterns):\n",
    "    corners = []\n",
    "    for p in patterns:\n",
    "        corners.append(find_box_with_pattern(target_img, p))\n",
    "    return corners\n",
    "\n",
    "def find_for_all_patterns_resize(target_img, patterns):\n",
    "    corners = []\n",
    "    factors = [1.5, 1, 0.5]\n",
    "    for p in patterns:\n",
    "        for f in factors:\n",
    "            resized_pattern = resize_with_factor(p, f)\n",
    "            resized_dim = (resized_pattern.shape[1], resized_pattern.shape[0])\n",
    "            target_dim = (target_img.shape[1], target_img.shape[0])\n",
    "            if (resized_dim[0] < target_dim[0] and resized_dim[1] < target_dim[1]):\n",
    "                corner = find_box_with_pattern(target_img, resized_pattern)\n",
    "                if (corner is not None):\n",
    "                    corners.append(corner)\n",
    "    return corners    \n",
    "\n",
    "def show_labeled_image_with_corners(target_img, corners):\n",
    "    \n",
    "    showed_img = target_img.copy()\n",
    "    \n",
    "    for c in corners:\n",
    "        cv.rectangle(showed_img, c[0], c[1], (0, 0, 255), 2)\n",
    "        \n",
    "    cv.imshow('image', showed_img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corners = find_for_all_patterns_resize(target_img, patterns_imgs)\n",
    "show_labeled_image_with_corners(target_img_colored, corners)\n",
    "print(len(corners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-5339130.5 9971164.0\n",
    "-2493280.25 5092399.0\n",
    "-711466.3125 1087420.875\n",
    "-5530162.0 11429691.0\n",
    "-2805763.0 5570730.0\n",
    "-838670.375 1135935.375\n",
    "-10501176.0 15898986.0\n",
    "-5398862.5 9481805.0\n",
    "-1354308.125 2192995.25\n",
    "-7610752.0 15590421.0\n",
    "-3614905.75 6865022.5\n",
    "-915325.375 1502020.75\n",
    "-8160000.0 17077074.0\n",
    "-3606160.0 7953486.5\n",
    "-1071434.25 1513853.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv.imread('flies.jpg',0)\n",
    "img2 = img.copy()\n",
    "final_img = img.copy()\n",
    "template = cv.imread('fly.jpg',0)\n",
    "w, h = template.shape[::-1]\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "    # Apply template Matching\n",
    "    res = cv.matchTemplate(img, template, method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv.rectangle(img,top_left, bottom_right, (0, 0, 0), 2)\n",
    "    cv.rectangle(final_img,top_left, bottom_right, (255, 0, 0), 2)\n",
    "    plt.subplot(121),plt.imshow(final_img)\n",
    "    #plt.subplot(121), plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122), plt.imshow(img, cmap = 'gray')\n",
    "    \n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
