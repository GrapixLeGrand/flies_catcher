{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cython\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 64, 3)\n",
      "(48, 64)\n",
      "t =  56  ms\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('flies.jpg')\n",
    "\n",
    "\n",
    "#pipeline constants\n",
    "replacement_vector = [255, 255, 255]\n",
    "distance_threshold = 10\n",
    "grayscale_threshold = 120\n",
    "scale_percent = 25\n",
    "blur_kernel_size = (4, 4)\n",
    "BLOBS_SIZES_BOUNDS = (7, 10)\n",
    "\n",
    "#for the blob detection\n",
    "params = cv.SimpleBlobDetector_Params()\n",
    "params.filterByConvexity = False\n",
    "params.filterByCircularity = False\n",
    "params.filterByInertia = False\n",
    "params.filterByArea = False\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "this method takes a vector of rgb components @rgb_vec and\n",
    "replace it with @replace if the average absolute difference\n",
    "with each component regarding the average of the components\n",
    "exceeds the threshold. In other word, this function aim to\n",
    "replace the vector by another if the pixel is not as grayscaled\n",
    "as we want\n",
    "\"\"\"\n",
    "def compute_avg_diff_comp(rgb_vec, replace, thresh):\n",
    "    assert(rgb_vec.shape[0] == 3)\n",
    "    mean = np.mean(rgb_vec)\n",
    "    sub = np.abs(rgb_vec - mean)\n",
    "    sub_mean = np.max(sub)\n",
    "    if (sub_mean < thresh):\n",
    "        return rgb_vec\n",
    "    else:\n",
    "        return replace\n",
    "        \n",
    "\"\"\"\n",
    "this methods takes an image and filter it with @compute_avg_diff_comp\n",
    "the resulting image is an image where the pixels not satisfying the threshod\n",
    "are full white.\n",
    "\"\"\"\n",
    "def filter_image_thresh(img):\n",
    "    global replacement_vector\n",
    "    global distance_threshold\n",
    "    replace_vec = np.array(replacement_vector, dtype=np.uint8)\n",
    "    result = []\n",
    "    for i in range(0, len(img)):\n",
    "        for j in range(0, len(img[0])):\n",
    "            rgb_vec = img[i][j]\n",
    "            result.append(compute_avg_diff_comp(rgb_vec, replace_vec, distance_threshold))\n",
    "    result = np.asarray(result, dtype=np.uint8)\n",
    "    result = result.reshape((img.shape[0], img.shape[1], img.shape[2]))\n",
    "    return result\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "convert an rgb numpy array to a grayscale numpy array\n",
    "the type must be uint8 for each component\n",
    "\"\"\"\n",
    "def convert_rgb_to_grayscale(img):\n",
    "    print(img.shape)\n",
    "    i = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    print(i.shape)\n",
    "    return i\n",
    "\n",
    "def convert_bgr_to_rgb(img):\n",
    "    return cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "\"\"\"\n",
    "given a grayscale image, set the pixel having \n",
    "brightness greater than threshold to white\n",
    "\"\"\"\n",
    "def apply_threshold_grayscale(img):\n",
    "    global grayscale_threshold\n",
    "    img[img > grayscale_threshold] = 255\n",
    "    return img\n",
    "\n",
    "\"\"\"\n",
    "set all non white pixels to black\n",
    "\"\"\"\n",
    "def apply_threshold_set_black(img):\n",
    "    img[img != 255] = 0\n",
    "    return img\n",
    "\n",
    "\n",
    "def resize_img(img):\n",
    "    global scale_percent\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "    return resized\n",
    "\n",
    "def low_pass_filter_img(img):\n",
    "    global blur_kernel_size\n",
    "    return cv.blur(img, blur_kernel_size)\n",
    "\n",
    "\"\"\"\n",
    "find all the blobs in the image and highlight them.\n",
    "We also return a list of the blob sizes\n",
    "\"\"\"\n",
    "def find_blobs(img):\n",
    "    global params\n",
    "    detector = cv.SimpleBlobDetector_create(params)\n",
    "    keypoints = detector.detect(img)\n",
    "    blobs_sizes = []\n",
    "    for k in keypoints:\n",
    "        blobs_sizes.append(k.size)\n",
    "    blobs_sizes = np.array(blobs_sizes)\n",
    "    return cv.drawKeypoints(img, keypoints, np.array([]), (0,0,255), cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS), blobs_sizes\n",
    "\n",
    "\n",
    "def set_image_boarders(img, value):\n",
    "    w = img.shape[1]\n",
    "    h = img.shape[0]\n",
    "    img[0, :, ] = value\n",
    "    img[h - 1, :, ] = value\n",
    "    img[:, 0, ] = value\n",
    "    img[:, w - 1, ] = value\n",
    "    return img\n",
    "\n",
    "\"\"\"\n",
    "this function removes any external layer of pixel in the border of the\n",
    "image. This is helpful for the blob detection part.\n",
    "\"\"\"\n",
    "def set_boarders_white(img):\n",
    "    return set_image_boarders(img, 255)\n",
    "\n",
    "\n",
    "def set_boarders_black(img):\n",
    "    return set_image_boarders(img, 0)\n",
    "\n",
    "\"\"\"\n",
    "preproessing pipeline:\n",
    "\n",
    "1. we resize the image \n",
    "    This allows us to remove a bit of noise and to allows more efficient calculations\n",
    "2. We filter the colored objects to white\n",
    "    Since a fly is gray to black we want to get rid of all the colored pixels in the image\n",
    "3. We convert the resulting image to grayscale because now all three components are almost equal\n",
    "4. We filter pixels by their brightness since a fly is dark\n",
    "5. We filter all non white pixels to black because each non white pixel at this point is a good\n",
    "    candidate for belonging to a fly\n",
    "6. We blur the image to remove high frequency data occuring\n",
    "7. We filter again all non white pixel to black, this enlight area of interest\n",
    "\n",
    "Since we are finding patterns in image, its easier to find them with simple geometric form like\n",
    "a black disk. Therefore the pipeline above helps us to convert files to black areas that looks like\n",
    "circles\n",
    "\n",
    "\"\"\"\n",
    "pipeline = [\n",
    "    (resize_img, \"resized\", True),\n",
    "    (filter_image_thresh, \"filter colored pixel\", True),\n",
    "    (convert_rgb_to_grayscale, \"convert to grayscale\", False),\n",
    "    (apply_threshold_grayscale, \"threshold brightness\", False),\n",
    "    (apply_threshold_set_black, \"set non white to black\", False),\n",
    "    (low_pass_filter_img, \"blurred\", False),\n",
    "    (apply_threshold_set_black, \"set non white to black again\", False),\n",
    "    (set_boarders_white, \"remove external pixel line\", False),\n",
    "    (find_blobs, \"find blobs on image\", True)\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "pipeline processing the image in order to prepare it to be detected\n",
    "this function should only be used in a python notebook\n",
    "\"\"\"\n",
    "def preprocessing_pipeline_matplotlib(img):\n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(len(pipeline) + 1,1, figsize=(40, 40)) \n",
    "    axarr[0].set_title(\"orignial input\")\n",
    "    axarr[0].imshow(img)\n",
    "    for i in range(1, len(pipeline)):\n",
    "        pipeline_func = pipeline[i]\n",
    "        func = pipeline_func[0]\n",
    "        if (i < len(pipeline) - 1):\n",
    "            img = func(img)\n",
    "        else:\n",
    "            img, _ = func(img)\n",
    "            \n",
    "        if (pipeline_func[2]):\n",
    "            axarr[i].imshow(img)\n",
    "        else:\n",
    "            axarr[i].imshow(img, cmap = plt.cm.gray)\n",
    "        axarr[i].set_title(pipeline_func[1])\n",
    "    plt.show()\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "#plt.figure()\n",
    "#f, axarr = plt.subplots(len(pipeline) + 1,1, figsize=(40, 40)) \n",
    "#preprocessed_img = preprocessing_pipeline_matplotlib(convert_bgr_to_rgb(img))\n",
    "\n",
    "#plt.show()\n",
    "#preprocessing_pipeline_matplotlib(convert_bgr_to_rgb(img))\n",
    "\n",
    "\"\"\"returns an image with all the pipeline\"\"\"\n",
    "def pipeline_opencv(img):\n",
    "    images = []\n",
    "    blob_sizes = None\n",
    "    for i in range(0, len(pipeline)):\n",
    "        pipeline_func = pipeline[i]\n",
    "        func = pipeline_func[0]\n",
    "        if (i < len(pipeline) - 1):\n",
    "            img = func(img)\n",
    "        else:\n",
    "            img, sizes = func(img)\n",
    "            blob_sizes = sizes\n",
    "        img_cpy_black_boarders = set_boarders_black(img.copy())\n",
    "        #if the output is colored or not\n",
    "        if (pipeline_func[2]):\n",
    "            images.append(img_cpy_black_boarders)\n",
    "        else:\n",
    "            images.append(cv.cvtColor(img_cpy_black_boarders, cv.COLOR_GRAY2BGR))\n",
    "    \n",
    "    return blob_sizes, np.concatenate(images, axis=1)\n",
    "\n",
    "starting_time = round(time.time() * 1000)\n",
    "blob_sizes, res = pipeline_opencv(img)\n",
    "print(\"t = \", str(round(time.time() * 1000) - starting_time), \" ms\")\n",
    "\n",
    "cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "cv.resizeWindow('result', 1500, 200)\n",
    "cv.imshow('result', res)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_external_line(img):\n",
    "    w = img.shape[1]\n",
    "    h = img.shape[0]\n",
    "    img[0, :, ] = 255\n",
    "    img[h - 1, :, ] = 255\n",
    "    img[:, 0, ] = 255\n",
    "    img[:, w - 1, ] = 255\n",
    "    return img\n",
    "    \n",
    "plt.imshow(remove_external_line(preprocessed_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save 06.06.21\n",
    "def compute_pattern(h, w):\n",
    "    return np.ones((h, w), np.uint8)\n",
    "\n",
    "pattern = compute_pattern(6, 6)\n",
    "\n",
    "def find_box_with_pattern(img, pattern):\n",
    "    \n",
    "    pattern_img_cpy = pattern.copy()\n",
    "    methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "    meth = methods[4]\n",
    "    w, h = pattern.shape[::-1]\n",
    "    \n",
    "    method = eval(meth)\n",
    "    current_target = img.copy()\n",
    "    neighborhood_img = cv.matchTemplate(current_target, pattern_img_cpy, method)\n",
    "    \n",
    "    return neighborhood_img\n",
    "\n",
    "result_img = find_box_with_pattern(preprocessed_img, pattern)\n",
    "resized = resize_img(img)\n",
    "resized_rgb = convert_bgr_to_rgb(resized)\n",
    "\n",
    "threshold = 0.01\n",
    "result_img = (result_img - np.std(result_img)) / np.mean(result_img)\n",
    "loc = np.where(result_img < threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv.rectangle(resized_rgb, pt, (pt[0] + 1, pt[1] + 1), (0,0,255), 1)\n",
    "    \n",
    "plt.figure()\n",
    "f2, axarr2 = plt.subplots(1, 2, figsize=(15,15)) \n",
    "axarr2[0].imshow(result_img, cmap = plt.cm.gray)\n",
    "axarr2[1].imshow(resized_rgb)\n",
    "\n",
    "plt.show()\n",
    "np.max(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'flies2.jpg'\n",
    "patterns = ['fly.jpg', 'fly1.png', 'fly2.png', 'fly3.png', 'fly4.png']\n",
    "patterns = ['pattern/' + p for p in patterns]\n",
    "\n",
    "target_img = cv.imread(target, 0)\n",
    "target_img_colored = cv.imread(target)\n",
    "\n",
    "target_dim = (target_img.shape[1], target_img.shape[0])\n",
    "fly_dim_pixel = (target_dim[0] // 7, target_dim[1] // 5)\n",
    "\n",
    "print(target_dim)\n",
    "print(fly_dim_pixel)\n",
    "\n",
    "patterns_imgs = [ cv.imread(p,0) for p in patterns]\n",
    "\n",
    "\"\"\"resize the images so that they are in the target\"\"\"\n",
    "def resize_for_target(img, target_dim):\n",
    "    return cv.resize(img, target_dim, interpolation = cv.INTER_AREA)\n",
    "\n",
    "def resize_with_factor(img, factor):\n",
    "    dim = (img.shape[1], img.shape[0])\n",
    "    dim = (int(dim[0] * factor), int(dim[1] * factor))\n",
    "    return cv.resize(img, dim, interpolation = cv.INTER_AREA)\n",
    "\n",
    "patterns_imgs = [resize_for_target(p, fly_dim_pixel) for p in patterns_imgs]\n",
    "    \n",
    "\"\"\"Find the pattern in the target and returns the top-left and bottom right corners if found\"\"\"\n",
    "def find_box_with_pattern(target_img, pattern_img):\n",
    "    pattern_img_cpy = pattern_img.copy()\n",
    "    methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "    meth = methods[0]\n",
    "    w, h = pattern_img.shape[::-1]\n",
    "    \n",
    "    method = eval(meth)\n",
    "    current_target = target_img.copy()\n",
    "    result = cv.matchTemplate(current_target, pattern_img_cpy, method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "        \n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "            \n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    \n",
    "    print(str(min_val) + \" \" + str(max_val))\n",
    "    \n",
    "    if (max_val < 7000000):\n",
    "        return None\n",
    "    \n",
    "    return (top_left, bottom_right)\n",
    "\n",
    "\n",
    "\"\"\"find a set of corners matching the patterns in the target\"\"\"\n",
    "def find_for_all_patterns(target_img, patterns):\n",
    "    corners = []\n",
    "    for p in patterns:\n",
    "        corners.append(find_box_with_pattern(target_img, p))\n",
    "    return corners\n",
    "\n",
    "def find_for_all_patterns_resize(target_img, patterns):\n",
    "    corners = []\n",
    "    factors = [1.5, 1, 0.5]\n",
    "    for p in patterns:\n",
    "        for f in factors:\n",
    "            resized_pattern = resize_with_factor(p, f)\n",
    "            resized_dim = (resized_pattern.shape[1], resized_pattern.shape[0])\n",
    "            target_dim = (target_img.shape[1], target_img.shape[0])\n",
    "            if (resized_dim[0] < target_dim[0] and resized_dim[1] < target_dim[1]):\n",
    "                corner = find_box_with_pattern(target_img, resized_pattern)\n",
    "                if (corner is not None):\n",
    "                    corners.append(corner)\n",
    "    return corners    \n",
    "\n",
    "def show_labeled_image_with_corners(target_img, corners):\n",
    "    \n",
    "    showed_img = target_img.copy()\n",
    "    \n",
    "    for c in corners:\n",
    "        cv.rectangle(showed_img, c[0], c[1], (0, 0, 255), 2)\n",
    "        \n",
    "    cv.imshow('image', showed_img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corners = find_for_all_patterns_resize(target_img, patterns_imgs)\n",
    "show_labeled_image_with_corners(target_img_colored, corners)\n",
    "print(len(corners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-5339130.5 9971164.0\n",
    "-2493280.25 5092399.0\n",
    "-711466.3125 1087420.875\n",
    "-5530162.0 11429691.0\n",
    "-2805763.0 5570730.0\n",
    "-838670.375 1135935.375\n",
    "-10501176.0 15898986.0\n",
    "-5398862.5 9481805.0\n",
    "-1354308.125 2192995.25\n",
    "-7610752.0 15590421.0\n",
    "-3614905.75 6865022.5\n",
    "-915325.375 1502020.75\n",
    "-8160000.0 17077074.0\n",
    "-3606160.0 7953486.5\n",
    "-1071434.25 1513853.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv.imread('flies.jpg',0)\n",
    "img2 = img.copy()\n",
    "final_img = img.copy()\n",
    "template = cv.imread('fly.jpg',0)\n",
    "w, h = template.shape[::-1]\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "    # Apply template Matching\n",
    "    res = cv.matchTemplate(img, template, method)\n",
    "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv.rectangle(img,top_left, bottom_right, (0, 0, 0), 2)\n",
    "    cv.rectangle(final_img,top_left, bottom_right, (255, 0, 0), 2)\n",
    "    plt.subplot(121),plt.imshow(final_img)\n",
    "    #plt.subplot(121), plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122), plt.imshow(img, cmap = 'gray')\n",
    "    \n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
